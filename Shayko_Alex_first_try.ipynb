{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xBM7bpPVHxFz"
      },
      "outputs": [],
      "source": [
        "url = 'https://mdk-arbat.ru/catalog/?subj_id=3217'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib, requests, socket, re, lxml, io, bs4, sqlite3, pandas, sqlalchemy\n",
        "from bs4 import BeautifulSoup\n",
        "from requests.compat import urljoin, quote_plus, urlparse, unquote\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36 Edg/134.0.0.0',\n",
        "    'Accept-Language': 'ru,en;q=0.9,en-GB;q=0.8,en-US;q=0.7',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "    'Referer': 'https://mdk-arbat.ru/catalog?subj_id=47',\n",
        "    'Connection': 'keep-alive',\n",
        "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
        "}\n",
        "html = requests.get(url, headers=headers).text\n",
        "soup = BeautifulSoup(html, 'lxml')"
      ],
      "metadata": {
        "id": "k_2jrR53H8Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_links=[]\n",
        "book_prices=[]\n",
        "book_genres=[]\n",
        "book_names=[]\n",
        "book_authors=[]\n",
        "book_publishers=[]\n",
        "\n",
        "\n",
        "\n",
        "for genre_tag in soup.find_all('ul', class_='tg-bookscategories'):\n",
        "    genre = genre_tag.find('a').text\n",
        "    book_genres.append(genre)\n",
        "\n",
        "for book_tag in soup.find_all('div', class_='tg-booktitle'):\n",
        "    book_title = book_tag.find('a').text\n",
        "    book_link = urljoin(url, book_tag.find('a')['href'])\n",
        "    book_names.append(book_title)\n",
        "    book_links.append(book_link)\n",
        "\n",
        "for book_author in soup.find_all('span', class_='tg-bookwriter'):\n",
        "  author = book_author.find('a').text\n",
        "  book_authors.append(author)\n",
        "\n",
        "for book_price in soup.find_all('span', class_='tg-bookprice'):\n",
        "  price = book_price.find('ins').text[:-1].strip()\n",
        "  book_prices.append(price)\n",
        "\n",
        "for link in book_links:\n",
        "  html_book = requests.get(link, headers=headers).text\n",
        "  soup_book = BeautifulSoup(html_book, 'lxml')\n",
        "  publisher = soup_book.find('meta', itemprop='publisher')['content']\n",
        "  book_publishers.append(publisher)\n",
        "\n",
        "# и тут я понял, что все странно парсится - книги совершенно не те, которые по ссылке. Поэтому погнали ботать селениум"
      ],
      "metadata": {
        "id": "JIUpNUUKNQqQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gWqbCJCzcZyo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}